人工智能迎来了继上世纪九十年代以来的又一次大发展，人工智能和深度学习无疑是近年来最受追捧的热点。2016年和2017年AlphaGo两次战胜韩国和中国围棋国手，更是让人工智能成为街头巷尾的热谈。为什么人工智能在经历了两起两落后再一次迎来了复兴，我认为，这一次的爆发主要由理论、应用、硬件和软件四个方面的原因促成的，貌似偶然实则必然。

Geoff Hinton等人在2006年发现了训练高层神经网络的有效算法，为深度学习的研究打开了新局面，也是人工智能得以重燃的导火线。经过后续研究人员的努力，尤其是CNN和RNN的出现，深度学习、神经网络方法在图像和语音识别方面显示出非常好的效果，大大超越之前的理论和方法，甚至能够突破人类极限。与计算机视觉、机器人、自然语言理解、信息检索等技术相结合，深度学习的应用也从单纯的图像和语音识别扩展到自动驾驶、图像增强与风格替换、文本语音间转换和推荐系统等。使用深度学习技术的应用和初创企业如雨后春笋般冒了出来。尤其需要指出的是，互联网和大数据的广泛应用是深度学习发展的必要条件。一般而言，数据量越大且数据质量越高，由深度学习训练出来的模型精度也就越好。计算机硬件的发展也直接推动了深度学习的发展。GPU和其他专用加速器件的出现，大大提高了深度学习的计算效率。在语音识别场景下，GPU可将数十亿样本的训练时间从数年缩短到数天。而专用的ASIC加速芯片相比GPU的能效更有数量级以上提升，也让深度学习从服务器端走向手机端，进一步拓展了其应用范围。

开放的软件生态和易用的软件形态是形成人工智能和深度学习产业链至关重要的两个方面。没有软件的支撑，理论很难与应用相结合，新硬件也很难为应用提速。从大数据软件的发展历程可以想见，如果没有开源的Hadoop生态系统，以及受其设计思想影响的新型大规模并行处理数据库系统，我们现在可能还在为如何管理和处理PB乃至EB级的数据发愁。开源TensorFlow的出现解决了类似的问题，一下子拉近了深度学习理论与实际应用的距离。同时，TensorFlow也具备迈向成功生态系统的必要条件，即差异化的软件功能，刚需的典型应用和活跃的社区支持，发展前景可期。但是，原生TensorFlow的软件形态尚不足以支持深度学习的全流程生产化应用，欠缺诸如数据管理和预处理，模型训练、管理和运行，资源管理、任务调度和运行时监控等能力，导致最终用户形成生产力的成本过高。深度学习是计算密集型重资产类应用，如果有能够提供异构高性能计算资源并能够集成上述平台化功能的深度学习公有云服务，可降低TensorFlow的使用门槛并提升用户体验，客观上会与开源效应叠加起到倍速产业发展的作用。

很高兴能够在这个时候看到一本讲授如何使用TensorFlow的专业书籍。作者是深谙计算机系统之道的一线工程师，带给读者的是产生自实战经验基础上的理解。非常难得的是，本书除了讲解如何使用TensorFlow还加入了对系统设计原理方面的剖析，有助于读者做针对性的应用和系统优化。相信本书对从事深度学习方面研究和开发的读者定会有所裨益。

查礼
中国科学院计算技术研究所 副研究员
中国大数据技术大会（BDTC） 发起人
2018年元旦于北京
